=== Summarization Report AA1662 ===

Article path: 'articles/1301.3781.pdf'
Model: google-t5/t5-small
Tokenizer: google-t5/t5-small
Context window: 512
LoRA: None
Gen time: 2025-04-06 17:40:55
Keywords: ['word', 'words', 'model', 'vectors', 'training']

-------------------------------------------------------------------------------------------------------
Simple models trained on huge amounts of data outperform complex systems trained on less data. But
the simple techniques are at their limits in many tasks. For example, the amount of relevant
indomain data for automatic speech recognition is limited.
-------------------------------------------------------------------------------------------------------

Statistics:
----------
word_count_summary: 44
word_count_full: 5926
sentence_count_summary: 3
sentence_count_full: 192
input_token_count: 512
output_token_count: 54
compression_rate: 0.77%
